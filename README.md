# ASLReader

## About the Project

This project was made for an internship at Mangofarm Assets. The goal was to create a Convolutional Neural Network to recognize images (or break a video into images and recognize them). The model currently is able to read American Sign Language (ASL), with 29 catgories representing each letter, as well as a few special characters, but it can be configured to recognize any type of image with any number of categories.

## About the Repository

The repository contains two Convolutional Neural Networks -- one made using the Keras library, and the other created from scratch, both of which are made using Python. The Keras model is more accurate, but the other model is completely programmed by me, with guidance from my mentor. 

## Prerequisites

A collection of images used for training and testing must be inputted into the folder titled "Database," and ordered into separate categorical files. They do not need to be split into separate training and testing folders, as that is done by the program. 


## Usage

## Future Implimentations
